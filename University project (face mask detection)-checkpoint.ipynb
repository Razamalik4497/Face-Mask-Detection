{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southwest-difficulty",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES AND MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handled-updating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait... \n",
      " ----- Model and Libraries are importing---- \n"
     ]
    }
   ],
   "source": [
    "### IMPORT PACKAGES\n",
    "\n",
    "print ( \"Please wait... \\n ----- Model and Libraries are importing---- \")\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "###  LOADING TRAINED MODEL \n",
    "model = load_model('inceptionV3-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thrown-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define height and width of image which pass through the model \n",
    "# Load the Cascade face Classifier\n",
    "\n",
    "img_width, img_hight = 100, 100\n",
    "face_cascade = cv2.CascadeClassifier(\"D:/Uni Project/live mask detection app/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "### make function for image detection\n",
    "\n",
    "def action1():\n",
    "  \n",
    "    # Define parameter for text styling\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    org = (1, 1)\n",
    "    class_lable=' '      \n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    img_count=1\n",
    "\n",
    "    # Importe Images from the path \n",
    "    # images Converte into grayscale\n",
    "    # Detect the faces with Cascade detectMultiScale\n",
    "\n",
    "    image_path = glob.glob(\"D:/Uni Project/live mask detection app/images/*.jpg\")\n",
    "   \n",
    "    for image in image_path:\n",
    "        color_img=cv2.imread(image)\n",
    "        gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_img, 1.1, 6) \n",
    "\n",
    "        # (x=axis, y=axis , w=width, h=height) find four point to make rectangle on face \n",
    "        # display color images after detecting face area, which is passed throuhg gray images\n",
    "        # images save in the directory \n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            org = (x-10,y-10) \n",
    "            print(img_count)\n",
    "            color_face = color_img[y:y+h,x:x+w] \n",
    "            cv2.imwrite('D:/Uni Project/detected images/images from images/input/%dface.jpg'%(img_count),color_face)\n",
    "            img = load_img('D:/Uni Project/detected images/images from images/input/%dface.jpg'%(img_count), target_size=(img_width,img_hight))\n",
    "            img_count+=1\n",
    "\n",
    "            # Convert image into array for the purpose of prediction  \n",
    "            \n",
    "            img = img_to_array(img)/255\n",
    "            img = np.expand_dims(img,axis=0)\n",
    "            pred_prob = model.predict(img)\n",
    "            pred=np.argmax(pred_prob)\n",
    "\n",
    "\n",
    "            # 'without mask' images save in appropriate folder\n",
    "            # 'with mask' images save in appropriate folder\n",
    "            \n",
    "            if pred==0:\n",
    "                print(\"User without mask - predic = \",pred_prob[0][0])\n",
    "                class_lable = \"No Mask\"\n",
    "                color = (255, 0, 0)\n",
    "                cv2.imwrite('D:Uni Project/detected images/images from images/without mask/%dface.jpg'%(img_count),color_face)\n",
    "                cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "                # Using cv2.putText() method \n",
    "                cv2.putText(color_img, class_lable, org, font,fontScale, color, thickness, cv2.LINE_AA)            \n",
    "            else:\n",
    "                print('user with mask - prob = ',pred_prob[0][1])\n",
    "                class_lable = \"Mask\"\n",
    "                color = (0, 255, 0)\n",
    "                cv2.imwrite('D:/Uni Project/detected images/images from images/with mask/%dface.jpg'%(img_count),color_face)\n",
    "                cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "                # Using cv2.putText() method \n",
    "                cv2.putText(color_img, class_lable, org, font,fontScale, color, thickness, cv2.LINE_AA) \n",
    "                \n",
    "# make function for image detection through webcam  \n",
    "\n",
    "def action2():\n",
    "    \n",
    "    # capture images from webcam\n",
    "    # Define parameter for text styling\n",
    "\n",
    "    cap = cv2.VideoCapture(0) \n",
    "    img_count_full = 0\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    org = (1, 1)\n",
    "    class_lable=' '      \n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    \n",
    "    \n",
    "    while(True):\n",
    "        img_count_full += 1\n",
    "\n",
    "        #read image from webcam\n",
    "        # Convert to grayscale\n",
    "        # Detect the faces with Cascade detectMultiScale\n",
    "        \n",
    "        responce, color_img = cap.read()\n",
    "        gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_img, 1.1, 6)\n",
    "\n",
    "        # (x=axis, y=axis , w=width, h=height) find four point to make rectangle on face \n",
    "        # display color images after detecting face area, which is passed throuhg gray images\n",
    "        # images save in the directory \n",
    "        \n",
    "        img_count = 0\n",
    "        for (x, y, w, h) in faces:\n",
    "            org = (x-10,y-10)\n",
    "            img_count +=1 \n",
    "            color_face = color_img[y:y+h,x:x+w] \n",
    "            cv2.imwrite('D:/Uni Project/detected images/images from live stream/input/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
    "            img = load_img('D:/Uni Project/detected images/images from live stream/input/%d%dface.jpg'%(img_count_full,img_count), target_size=(img_width,img_hight))\n",
    "\n",
    "            img = img_to_array(img)/255\n",
    "            img = np.expand_dims(img,axis=0)\n",
    "            pred_prob = model.predict(img)\n",
    "            #print(pred_prob[0][0].round(2))\n",
    "            pred=np.argmax(pred_prob)\n",
    "\n",
    "            # 'without mask' images save in appropriate folder\n",
    "            # 'with mask' images save in appropriate folder\n",
    "            \n",
    "            if pred==0:\n",
    "                print(\"User without mask - predic = \",pred_prob[0][0])\n",
    "                class_lable = \"No Mask\"\n",
    "                color = (255, 0, 0)\n",
    "                cv2.imwrite('D:/Uni Project/detected images/images from live stream/without mask/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
    "            else:\n",
    "                print('user with mask - prob = ',pred_prob[0][1])\n",
    "                class_lable = \"Mask\"\n",
    "                color = (0, 255, 0)\n",
    "                cv2.imwrite('D:/Uni Project/detected images/images from live stream/with mask/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
    "\n",
    "            # Opencv method rectangle() & putText()\n",
    "            # all text parameter is defined above  \n",
    "            \n",
    "            cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "            cv2.putText(color_img, class_lable, org, font,  \n",
    "            fontScale, color, thickness, cv2.LINE_AA) \n",
    "\n",
    "        # Display the image window \n",
    "            \n",
    "        cv2.imshow('LIVE face mask detection', color_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# make function for image detection through Recorded video\n",
    "def action3():\n",
    "    \n",
    "    # path of video \n",
    "    # Define parameter for text styling\n",
    "    \n",
    "    cap = cv2.VideoCapture('D:/Uni Project/live mask detection app/videos/my_video.mp4') # for video\n",
    "    img_count_full = 0\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    org = (1, 1)\n",
    "    class_lable=' '      \n",
    "    fontScale = 1 \n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    \n",
    "    ## Start reading images and prediction\n",
    "    \n",
    "    while(True):\n",
    "        img_count_full += 1\n",
    "        \n",
    "        # read image from video\n",
    "        responce, color_img = cap.read()\n",
    "\n",
    "        #after complete the video it will terminate the reading \n",
    "        if responce == False:\n",
    "            break    \n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect the faces with Cascade detectMultiScale\n",
    "        faces = face_cascade.detectMultiScale(gray_img, 1.1, 6)\n",
    "\n",
    "        # (x=axis, y=axis , w=width, h=height) find four point to make rectangle on face \n",
    "        # display color images after detecting face area, which is passed throuhg gray images\n",
    "        # images save in the directory \n",
    "        img_count = 0\n",
    "        for (x, y, w, h) in faces:\n",
    "            org = (x-10,y-10)\n",
    "            img_count += 1 \n",
    "            color_face = color_img[y:y+h,x:x+w] \n",
    "            cv2.imwrite('D:/Uni Project/detected images/images from recorded video/input/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
    "            img = load_img('D:/Uni Project/detected images/images from recorded video/input/%d%dface.jpg'%(img_count_full,img_count), target_size=(img_width,img_hight))\n",
    "\n",
    "            # Rescale images for prediction purpose\n",
    "            \n",
    "            img = img_to_array(img)/255\n",
    "            img = np.expand_dims(img,axis=0)\n",
    "            pred_prob = model.predict(img)\n",
    "            pred=np.argmax(pred_prob)\n",
    "\n",
    "            # 'without mask' images save in appropriate folder\n",
    "            # 'with mask' images save in appropriate folder\n",
    "            \n",
    "            if pred==0:\n",
    "                print(\"User without mask - predic = \",pred_prob[0][0])\n",
    "                class_lable = \"No Mask\"\n",
    "                color = (255, 0, 0)\n",
    "                cv2.imwrite('D:/Uni Project/detected images/images from recorded video/without mask/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
    "            else:\n",
    "                print('user with mask - prob = ',pred_prob[0][1])\n",
    "                class_lable = \"Mask\"\n",
    "                color = (0, 255, 0)\n",
    "                cv2.imwrite('D:/Uni Project/detected images/images from recorded video/with mask/%d%dface.jpg'%(img_count_full,img_count),color_face)\n",
    "\n",
    "            # Opencv method rectangle() & putText()\n",
    "            # all text parameter is defined above  \n",
    "            \n",
    "            cv2.rectangle(color_img, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "            cv2.putText(color_img, class_lable, org, font, fontScale, color, thickness, cv2.LINE_AA) \n",
    "\n",
    "        # display image\n",
    "        cv2.imshow('LIVE face mask detection', color_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-receipt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ MODEL HAS BEEN LOADED ------- \n"
     ]
    }
   ],
   "source": [
    "    \n",
    "def processing():\n",
    "    print(\"-----------------------\")\n",
    "    print( \"  Under Proccessing\")   \n",
    "    print(\"-----------------------\")\n",
    "\n",
    "def completed():\n",
    "    print(\"-----------------------\")\n",
    "    print(\"job is completed\")\n",
    "    print(\"-----------------------\")    \n",
    "\n",
    "print(\" ------ MODEL HAS BEEN LOADED ------- \")\n",
    "user_input = input(\"Please Select anyone option \\n | 1 : Image Detection | \\n | 2 : webcam detection  | \\n | 3 : Recorded Frames |\\n\" )\n",
    "\n",
    "if user_input == '1':\n",
    "    print(\"| 1 : Image Detection |\")\n",
    "    processing()\n",
    "    print(action1())\n",
    "    completed()\n",
    "elif user_input == '2':\n",
    "    print(\"| 2 : webcam detection  |\")\n",
    "    processing()\n",
    "    print(action2())\n",
    "    completed()\n",
    "elif user_input == '3':\n",
    "    print(\"| 3 : Recorded Frames | \")\n",
    "    processing()\n",
    "    print(action3())\n",
    "    completed()\n",
    "else:\n",
    "    print(\"Invalid command \\n please Rerun the code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-contamination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
